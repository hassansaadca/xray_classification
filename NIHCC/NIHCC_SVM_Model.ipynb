{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#import xray_data #y data: 1 = NORMAL, 0 = PNEUMONIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86524 images in training set\n",
      "25596 images in test set\n",
      "valid tags for dataset:  ['Cardiomegaly', 'No Finding', 'Hernia', 'Infiltration', 'Nodule', 'Emphysema', 'Effusion', 'Atelectasis', 'Mass', 'Pneumothorax', 'Pleural_Thickening', 'Fibrosis', 'Consolidation', 'Edema', 'Pneumonia']\n"
     ]
    }
   ],
   "source": [
    "import NIHCC_xray_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and preprocess data\n",
    "Note: data is resized and preprocessed as it is read, as a memory optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "scale = 200\n",
    "# Kaggle data options\n",
    "#label_filter = ['NORMAL','PNEUMONIA','COVID19','TURBERCULOSIS']\n",
    "#NIHCC options\n",
    "label_filter = ['Cardiomegaly', 'No Finding', 'Hernia', 'Infiltration', \n",
    "                'Nodule', 'Emphysema', 'Effusion', 'Atelectasis', \n",
    "                'Mass', 'Pneumothorax', 'Pleural_Thickening', 'Fibrosis',\n",
    "                'Consolidation', 'Edema', 'Pneumonia']\n",
    "subset = 'PROP' # either \"EQL\" or \"PROP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (17853 of 17853) |##################| Elapsed Time: 0:00:47 Time:  0:00:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hernia: 2\n",
      "Mass: 24\n",
      "Pneumothorax: 53\n",
      "No Finding: 552\n",
      "Emphysema: 17\n",
      "Cardiomegaly: 17\n",
      "Infiltration: 124\n",
      "Pleural_Thickening: 17\n",
      "Effusion: 65\n",
      "Consolidation: 26\n",
      "Edema: 12\n",
      "Atelectasis: 44\n",
      "Fibrosis: 9\n",
      "Pneumonia: 4\n",
      "Nodule: 25\n",
      "Total: 991\n",
      "X_test, y_test shape: ((991, 40000), (991,))\n",
      "y_test shape for NORMAL cases: (552,)\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# cut of for training samples of each class, only 230 normal rows\n",
    "test_cutoff =1000\n",
    "\n",
    "X_test, y_test = NIHCC_xray_data.load_test(scale,label_filter,test_cutoff,subset=subset)\n",
    "print(f'X_test, y_test shape: {X_test.shape, y_test.shape}')\n",
    "print(f'y_test shape for NORMAL cases: {y_test[y_test ==1].shape}')\n",
    "print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (73471 of 73471) |##################| Elapsed Time: 0:09:03 Time:  0:09:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardiomegaly: 105\n",
      "No Finding: 6873\n",
      "Infiltration: 997\n",
      "Nodule: 305\n",
      "Emphysema: 79\n",
      "Effusion: 379\n",
      "Atelectasis: 464\n",
      "Pleural_Thickening: 111\n",
      "Fibrosis: 74\n",
      "Mass: 230\n",
      "Pneumonia: 31\n",
      "Pneumothorax: 168\n",
      "Hernia: 8\n",
      "Consolidation: 112\n",
      "Edema: 54\n",
      "Total: 9990\n"
     ]
    }
   ],
   "source": [
    "# cut of for training samples of each class, only 1300 normal rows\n",
    "train_cutoff = 10000\n",
    "\n",
    "X_train, y_train = NIHCC_xray_data.load_train(scale,label_filter,max_count=train_cutoff,subset=subset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2a: Adjust all image sets by mean/std of train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(mean,std) = xray_data.find_mean_std(X_train)\n",
    "#print(mean,std)\n",
    "#print(X_train.shape)\n",
    "#adjusted_X_train = xray_data.normalize_images(X_train,mean,std)\n",
    "#print (f'adjusted train {adjusted_X_train.shape}')\n",
    "#adjusted_X_dev_org = xray_data.normalize_images(X_dev_orig,mean,std)\n",
    "#adjusted_X_test = xray_data.normalize_images(X_test,mean,std)\n",
    "# uncomment to use rescaled data\n",
    "# X_train = adjusted_X_train\n",
    "# X_dev_org = adjusted_X_dev_orig\n",
    "# X_test = adjusted_X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b: Split data into dev and train\n",
    "Original dev data set is too small for much validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, y_train shape: ((8991, 40000), (8991,))\n",
      "y_train shape for NORMAL cases: (6186,)\n",
      "----\n",
      "X_dev, y_dev shape: ((999, 40000), (999,))\n",
      "y_dev shape for NORMAL cases: (687,)\n"
     ]
    }
   ],
   "source": [
    "# I'm not sure what the final stratify parameter is doing.  We'll want to revist when we do full cross validation\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size = .1, stratify = y_train )\n",
    "print(f'X_train, y_train shape: {X_train.shape, y_train.shape}')\n",
    "print(f'y_train shape for NORMAL cases: {y_train[y_train ==1].shape}')\n",
    "print('----')\n",
    "print(f'X_dev, y_dev shape: {X_dev.shape, y_dev.shape}')\n",
    "print(f'y_dev shape for NORMAL cases: {y_dev[y_dev ==1].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Single Model training\n",
    "\n",
    "Default values:  The default model for SVC is \n",
    " - C=1, \n",
    " - kernel='rbf', \n",
    " - gamma=1/(n_features * X.var()).  For a 200x200 rescale this results in gamma = .000025/X.var().  We may want to go with smaller gamma values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Model accuracy:    68.769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_model = svm.SVC()\n",
    "\n",
    "base_model.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = base_model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Model accuracy:    68.769\n",
      "Single Model f1_score:    81.495\n"
     ]
    }
   ],
   "source": [
    "print(f'Single Model accuracy: {accuracy_score(y_pred,y_dev)*100:9.5}')\n",
    "f1score = f1_score(y_pred,y_dev,average='weighted')\n",
    "\n",
    "print(f'Single Model f1_score: {f1score*100:9.5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4  CrossValidated Gridsearch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.687 total time=24.3min\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.688 total time=23.9min\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.688 total time=24.0min\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.688 total time=24.1min\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.688 total time=23.7min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [10], 'gamma': [0.0001], 'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid={'C':[10],'gamma':[0.0001],'kernel':['rbf']}\n",
    "\n",
    "svc = svm.SVC()\n",
    "CV_model = GridSearchCV(svc,param_grid,verbose=3)\n",
    "\n",
    "CV_model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:     68.78\n",
      "Best params: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best score: {CV_model.best_score_*100:9.5}')\n",
    "print(f'Best params: {CV_model.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = CV_model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Fit Model accuracy:    68.769\n",
      "Best Fit Model f1_score:    81.495\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Fit Model accuracy: {accuracy_score(y_pred,y_dev)*100:9.5}')\n",
    "\n",
    "f1score = f1_score(y_pred,y_dev,average='weighted')\n",
    "\n",
    "print(f'Best Fit Model f1_score: {f1score*100:9.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0, 687,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0, 100,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,  31,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,  38,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,  46,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,  23,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,  17,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_dev,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
